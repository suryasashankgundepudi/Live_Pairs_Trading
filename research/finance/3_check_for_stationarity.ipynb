{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-30T13:48:27.418381200Z",
     "start_time": "2023-10-30T13:48:27.414012200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for Stationarity for each pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import random\n",
    "import json\n",
    "import statsmodels.api as sm\n",
    "import datetime\n",
    "import os \n",
    "import csv\n",
    "import copy \n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "random.seed(1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T13:48:29.900032700Z",
     "start_time": "2023-10-30T13:48:27.418381200Z"
    }
   },
   "id": "773ee2908b289925"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Function: Load data obtained from the identify pairs notebook"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T13:48:29.908321300Z",
     "start_time": "2023-10-30T13:48:29.900032700Z"
    }
   },
   "id": "b5aaa4e9abe85461"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def load_pairs():\n",
    "    file_path = \"data/pairs_names.json\"\n",
    "    \n",
    "    # Read the JSON file as a dictionary\n",
    "    with open(file_path, \"r\") as json_file:\n",
    "        loaded_pairs_dic = json.load(json_file)\n",
    "    \n",
    "    # Now, loaded_pairs_dic contains the dictionary from the JSON file\n",
    "    #print(loaded_pairs_dic)\n",
    "    return loaded_pairs_dic\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T13:48:29.929536200Z",
     "start_time": "2023-10-30T13:48:29.908321300Z"
    }
   },
   "id": "ac95232b0e4efa59"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Enable to use start & end dates:\n",
    "start = datetime.date.today() - datetime.timedelta(days=430)\n",
    "end = datetime.date.today() - datetime.timedelta(days=60)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T13:48:29.940135500Z",
     "start_time": "2023-10-30T13:48:29.924345200Z"
    }
   },
   "id": "dddbd0a845280fd4"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Function: Plotting price movement of two assets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T13:48:29.940135500Z",
     "start_time": "2023-10-30T13:48:29.934547Z"
    }
   },
   "id": "fd90d2f5a9dc2e1e"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_assets(asset1, asset2, ticker1, ticker2):\n",
    "    fig = make_subplots(rows=2,\n",
    "                    cols=1,\n",
    "                    subplot_titles=(\"asset2\", \"asset1\"))\n",
    "\n",
    "    fig.append_trace(go.Scatter(x=asset2.index,\n",
    "                                y=asset2,\n",
    "                                ),\n",
    "                     row=1, col=1)\n",
    "    \n",
    "    fig.append_trace(go.Scatter(x=asset1.index,\n",
    "                                y=asset1,\n",
    "                                ),\n",
    "                     row=2, col=1)\n",
    "    \n",
    "    # Update yaxis properties\n",
    "    fig.update_yaxes(title_text=\"Price\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Date\",  row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Price\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Date\",  row=2, col=1)\n",
    "    \n",
    "    #fig.show()\n",
    "    if not os.path.exists(\"img/\"):\n",
    "        os.mkdir(\"img/\")\n",
    "        print(\"Image Directory Created!\")\n",
    "    \n",
    "    file_path = \"img/\" + ticker1 + \"_\" + ticker2 + \".html\" \n",
    "    fig.write_html(file_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T13:48:29.963646400Z",
     "start_time": "2023-10-30T13:48:29.940135500Z"
    }
   },
   "id": "b3289fb34c2aca02"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Function: Run OLS Regression and calculating spread"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T13:48:29.992919600Z",
     "start_time": "2023-10-30T13:48:29.970115800Z"
    }
   },
   "id": "6570c27b3cbf9044"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def regression_analysis(asset1, asset2, ticker1, ticker2):\n",
    "\n",
    "    # adding a constant variable to the asset1 time series for the intercept value \n",
    "    asset1 = sm.add_constant(asset1, prepend=False)\n",
    "    \n",
    "    # Running the OLS function with asset2 as the dependent variable and asset1 as the dependent variable\n",
    "    ols = sm.OLS(asset2, asset1)\n",
    "    \n",
    "    # Saving the results of the OLS model into a variable\n",
    "    output = ols.fit()\n",
    "    print(\"Completed Training\")\n",
    "    \n",
    "    #print(output.params)\n",
    "    # Getting the beta from the OLS results. Close means the close price of asset1\n",
    "    beta = output.params[\"Close\"]\n",
    "    \n",
    "    # Dropping the const column in the dependent variable\n",
    "    asset1.drop(columns=\"const\", inplace = True)\n",
    "    \n",
    "    # Calculating spread\n",
    "    spread = asset2 - beta*asset1[\"Close\"]\n",
    "    \n",
    "    fig = go.Figure(go.Scatter(y = spread))\n",
    "    \n",
    "    fig.update_layout(title = \"Spread between \" + ticker2 + \" and \" + ticker1)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Date\")\n",
    "    fig.update_yaxes(title_text=\"Spread\")\n",
    "    \n",
    "    file_path = \"img/Spread_\" + ticker1 + \"_\" + ticker2 + \".html\"\n",
    "    fig.write_html(file_path)\n",
    "    \n",
    "    #fig.show()\n",
    "    \n",
    "    return beta, spread\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T13:48:29.992919600Z",
     "start_time": "2023-10-30T13:48:29.971624300Z"
    }
   },
   "id": "e2581d18c879598e"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Function: Perform Augmented Dickey Fuller Test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T13:48:29.992919600Z",
     "start_time": "2023-10-30T13:48:29.987357700Z"
    }
   },
   "id": "97e94f3395a34290"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "def run_adf_test(ticker1, ticker2, spread, pvalue_thres):\n",
    "    result = adfuller(spread)\n",
    "    does_pass = result[1] < pvalue_thres\n",
    "    if does_pass:\n",
    "        print(f'spread between {ticker1} and {ticker2} passed ADF stationarity test')\n",
    "    else:\n",
    "        print(f'spread between {ticker1} and {ticker2} failed ADF stationarity test')    \n",
    "    return does_pass\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T13:48:30.015898800Z",
     "start_time": "2023-10-30T13:48:29.992919600Z"
    }
   },
   "id": "d7206e2b73b3acec"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "#1. p-value > 0.05: Fail to reject the null hypothesis (H0), the data has a unit root and is non-stationary.\n",
    "#2. p-value <= 0.05: Reject the null hypothesis (H0), the data does not have a unit root and is stationary.\n",
    "\n",
    "#**Since the p value is greater than 0.05 we fail to reject the null hypothesis, the time series is not stationary**\n",
    "\n",
    "#If it was accepted the code would be as follows\n",
    "#```python\n",
    "#accepted_pairs = []\n",
    "#accepted_pairs.append(target_pair[0] + \"_\" + target_pair[1]) \n",
    "#```\n",
    "\n",
    "#You don't need to print out the values from ADF just check if the 5% level is less than or equal to 0.05 and save it into the list. \n",
    "\n",
    "\n",
    "#Once the list is complete for all assets you would need to save it as a text file for later use"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T13:48:30.019407900Z",
     "start_time": "2023-10-30T13:48:30.005541600Z"
    }
   },
   "id": "58c00cb295dbf9f8"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ICE': ['HDB'], 'ING': ['HDB'], 'ITUB': ['BX'], 'JPM': ['APO', 'HDB'], 'MA': ['HDB', 'JPM'], 'MMC': ['ICE'], 'MS': ['C'], 'PYPL': ['HDB'], 'RY': ['BNS', 'MS'], 'SMFG': ['BBVA', 'HDB'], 'UBS': ['HDB', 'PGR', 'SMFG'], 'USB': ['TD'], 'V': ['BBVA', 'HDB', 'PYPL', 'SAN', 'UBS']}\n",
      "ICE_HDB\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between ICE and HDB failed ADF stationarity test\n",
      "ING_HDB\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between ING and HDB failed ADF stationarity test\n",
      "ITUB_BX\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between ITUB and BX failed ADF stationarity test\n",
      "JPM_APO\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between JPM and APO passed ADF stationarity test\n",
      "JPM_HDB\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between JPM and HDB failed ADF stationarity test\n",
      "MA_HDB\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between MA and HDB passed ADF stationarity test\n",
      "MA_JPM\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between MA and JPM passed ADF stationarity test\n",
      "MMC_ICE\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between MMC and ICE passed ADF stationarity test\n",
      "MS_C\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between MS and C passed ADF stationarity test\n",
      "PYPL_HDB\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between PYPL and HDB passed ADF stationarity test\n",
      "RY_BNS\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between RY and BNS passed ADF stationarity test\n",
      "RY_MS\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between RY and MS passed ADF stationarity test\n",
      "SMFG_BBVA\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between SMFG and BBVA passed ADF stationarity test\n",
      "SMFG_HDB\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between SMFG and HDB passed ADF stationarity test\n",
      "UBS_HDB\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between UBS and HDB failed ADF stationarity test\n",
      "UBS_PGR\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between UBS and PGR passed ADF stationarity test\n",
      "UBS_SMFG\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between UBS and SMFG failed ADF stationarity test\n",
      "USB_TD\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between USB and TD passed ADF stationarity test\n",
      "V_BBVA\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between V and BBVA passed ADF stationarity test\n",
      "V_HDB\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between V and HDB passed ADF stationarity test\n",
      "V_PYPL\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between V and PYPL passed ADF stationarity test\n",
      "V_SAN\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between V and SAN passed ADF stationarity test\n",
      "V_UBS\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between V and UBS passed ADF stationarity test\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "def get_data(ticker, start, end):\n",
    "    return yf.download(ticker, start, end)['Close']\n",
    "\n",
    "def main():\n",
    "    final_pair_list = []\n",
    "    adf_pvalue_thres = 0.05\n",
    "    pair_to_spread = {} \n",
    "    \n",
    "    pairs_dict = load_pairs()\n",
    "    print(pairs_dict)\n",
    "\n",
    "    for ticker1 in pairs_dict.keys():\n",
    "        tickers = copy.copy(pairs_dict[ticker1])\n",
    "        if isinstance(tickers, str):\n",
    "            tickers = [tickers]\n",
    "            \n",
    "        for ticker2 in tickers:\n",
    "            pair_name = ticker1 + '_' + ticker2\n",
    "            print(pair_name)\n",
    "            asset1 = get_data(ticker1,start,end)\n",
    "            asset2 = get_data(ticker2,start,end)\n",
    "            plot_assets(asset1, asset2, ticker1, ticker2)\n",
    "            pair_to_spread[pair_name], spread = regression_analysis(asset1, asset2, ticker1, ticker2)\n",
    "            does_pass_adf = run_adf_test(ticker1,ticker2,spread, adf_pvalue_thres)\n",
    "            if does_pass_adf:\n",
    "                final_pair_list.append(ticker1+\"_\"+ticker2)\n",
    "    \n",
    "    print(len(final_pair_list))\n",
    "    final_pair_file_path = \"data/final_pair.csv\"\n",
    "    with open(final_pair_file_path, \"w\", newline=\"\") as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        for pair in final_pair_list:\n",
    "            tickers = pair.split(\"_\")\n",
    "            writer.writerow([tickers[0],tickers[1]])\n",
    "        \n",
    "main()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T13:48:44.795136200Z",
     "start_time": "2023-10-30T13:48:30.019407900Z"
    }
   },
   "id": "4d183ff655a03645"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
