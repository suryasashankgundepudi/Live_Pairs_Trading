{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-09T23:29:53.162383100Z",
     "start_time": "2023-10-09T23:29:53.076506600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for Stationarity for each pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import random\n",
    "import json\n",
    "import statsmodels.api as sm\n",
    "import datetime\n",
    "import os \n",
    "import csv\n",
    "import copy \n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "random.seed(1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T23:29:53.162383100Z",
     "start_time": "2023-10-09T23:29:53.076506600Z"
    }
   },
   "id": "773ee2908b289925"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "# Function: Load data obtained from the identify pairs notebook"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T23:29:53.162383100Z",
     "start_time": "2023-10-09T23:29:53.088562300Z"
    }
   },
   "id": "b5aaa4e9abe85461"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "def load_pairs():\n",
    "    file_path = \"data/pairs_names.json\"\n",
    "    \n",
    "    # Read the JSON file as a dictionary\n",
    "    with open(file_path, \"r\") as json_file:\n",
    "        loaded_pairs_dic = json.load(json_file)\n",
    "    \n",
    "    # Now, loaded_pairs_dic contains the dictionary from the JSON file\n",
    "    #print(loaded_pairs_dic)\n",
    "    return loaded_pairs_dic\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T23:29:53.213180900Z",
     "start_time": "2023-10-09T23:29:53.118391600Z"
    }
   },
   "id": "ac95232b0e4efa59"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "# Enable to use start & end dates:\n",
    "start = datetime.date.today() - datetime.timedelta(days=430)\n",
    "end = datetime.date.today() - datetime.timedelta(days=60)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T23:29:53.213180900Z",
     "start_time": "2023-10-09T23:29:53.118391600Z"
    }
   },
   "id": "dddbd0a845280fd4"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "# Function: Plotting price movement of two assets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T23:29:53.213180900Z",
     "start_time": "2023-10-09T23:29:53.134282900Z"
    }
   },
   "id": "fd90d2f5a9dc2e1e"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_assets(asset1, asset2, ticker1, ticker2):\n",
    "    fig = make_subplots(rows=2,\n",
    "                    cols=1,\n",
    "                    subplot_titles=(\"asset2\", \"asset1\"))\n",
    "\n",
    "    fig.append_trace(go.Scatter(x=asset2.index,\n",
    "                                y=asset2,\n",
    "                                ),\n",
    "                     row=1, col=1)\n",
    "    \n",
    "    fig.append_trace(go.Scatter(x=asset1.index,\n",
    "                                y=asset1,\n",
    "                                ),\n",
    "                     row=2, col=1)\n",
    "    \n",
    "    # Update yaxis properties\n",
    "    fig.update_yaxes(title_text=\"Price\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Date\",  row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Price\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Date\",  row=2, col=1)\n",
    "    \n",
    "    #fig.show()\n",
    "    if not os.path.exists(\"img/\"):\n",
    "        os.mkdir(\"img/\")\n",
    "        print(\"Image Directory Created!\")\n",
    "    \n",
    "    file_path = \"img/\" + ticker1 + \"_\" + ticker2 + \".html\" \n",
    "    fig.write_html(file_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T23:29:53.213180900Z",
     "start_time": "2023-10-09T23:29:53.150040500Z"
    }
   },
   "id": "b3289fb34c2aca02"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "# Function: Run OLS Regression and calculating spread"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T23:29:53.213180900Z",
     "start_time": "2023-10-09T23:29:53.152431400Z"
    }
   },
   "id": "6570c27b3cbf9044"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "def regression_analysis(asset1, asset2, ticker1, ticker2):\n",
    "\n",
    "    # adding a constant variable to the asset1 time series for the intercept value \n",
    "    asset1 = sm.add_constant(asset1, prepend=False)\n",
    "    \n",
    "    # Running the OLS function with asset2 as the dependent variable and asset1 as the dependent variable\n",
    "    ols = sm.OLS(asset2, asset1)\n",
    "    \n",
    "    # Saving the results of the OLS model into a variable\n",
    "    output = ols.fit()\n",
    "    print(\"Completed Training\")\n",
    "    \n",
    "    #print(output.params)\n",
    "    # Getting the beta from the OLS results. Close means the close price of asset1\n",
    "    beta = output.params[\"Close\"]\n",
    "    \n",
    "    # Dropping the const column in the dependent variable\n",
    "    asset1.drop(columns=\"const\", inplace = True)\n",
    "    \n",
    "    # Calculating spread\n",
    "    spread = asset2 - beta*asset1[\"Close\"]\n",
    "    \n",
    "    fig = go.Figure(go.Scatter(y = spread))\n",
    "    \n",
    "    fig.update_layout(title = \"Spread between \" + ticker2 + \" and \" + ticker1)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Date\")\n",
    "    fig.update_yaxes(title_text=\"Spread\")\n",
    "    \n",
    "    file_path = \"img/Spread_\" + ticker1 + \"_\" + ticker2 + \".html\"\n",
    "    fig.write_html(file_path)\n",
    "    \n",
    "    #fig.show()\n",
    "    \n",
    "    return beta, spread\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T23:29:53.213180900Z",
     "start_time": "2023-10-09T23:29:53.165889700Z"
    }
   },
   "id": "e2581d18c879598e"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# Function: Perform Augmented Dickey Fuller Test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T23:29:53.213180900Z",
     "start_time": "2023-10-09T23:29:53.184817700Z"
    }
   },
   "id": "97e94f3395a34290"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "def run_adf_test(ticker1, ticker2, spread, pvalue_thres):\n",
    "    result = adfuller(spread)\n",
    "    does_pass = result[1] < pvalue_thres\n",
    "    if does_pass:\n",
    "        print(f'spread between {ticker1} and {ticker2} passed ADF stationarity test')\n",
    "    else:\n",
    "        print(f'spread between {ticker1} and {ticker2} failed ADF stationarity test')    \n",
    "    return does_pass\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T23:29:53.213180900Z",
     "start_time": "2023-10-09T23:29:53.185321500Z"
    }
   },
   "id": "d7206e2b73b3acec"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "#1. p-value > 0.05: Fail to reject the null hypothesis (H0), the data has a unit root and is non-stationary.\n",
    "#2. p-value <= 0.05: Reject the null hypothesis (H0), the data does not have a unit root and is stationary.\n",
    "\n",
    "#**Since the p value is greater than 0.05 we fail to reject the null hypothesis, the time series is not stationary**\n",
    "\n",
    "#If it was accepted the code would be as follows\n",
    "#```python\n",
    "#accepted_pairs = []\n",
    "#accepted_pairs.append(target_pair[0] + \"_\" + target_pair[1]) \n",
    "#```\n",
    "\n",
    "#You don't need to print out the values from ADF just check if the 5% level is less than or equal to 0.05 and save it into the list. \n",
    "\n",
    "\n",
    "#Once the list is complete for all assets you would need to save it as a text file for later use"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T23:29:53.213180900Z",
     "start_time": "2023-10-09T23:29:53.197075600Z"
    }
   },
   "id": "58c00cb295dbf9f8"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mJSONDecodeError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[87], line 36\u001B[0m\n\u001B[0;32m     33\u001B[0m             tickers \u001B[38;5;241m=\u001B[39m pair\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     34\u001B[0m             writer\u001B[38;5;241m.\u001B[39mwriterow([tickers[\u001B[38;5;241m0\u001B[39m],tickers[\u001B[38;5;241m1\u001B[39m]])\n\u001B[1;32m---> 36\u001B[0m main()\n",
      "Cell \u001B[1;32mIn[87], line 9\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m      6\u001B[0m adf_pvalue_thres \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.05\u001B[39m\n\u001B[0;32m      7\u001B[0m pair_to_spread \u001B[38;5;241m=\u001B[39m {} \n\u001B[1;32m----> 9\u001B[0m pairs_dict \u001B[38;5;241m=\u001B[39m load_pairs()\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(pairs_dict)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ticker1 \u001B[38;5;129;01min\u001B[39;00m pairs_dict\u001B[38;5;241m.\u001B[39mkeys():\n",
      "Cell \u001B[1;32mIn[78], line 6\u001B[0m, in \u001B[0;36mload_pairs\u001B[1;34m()\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Read the JSON file as a dictionary\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(file_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m json_file:\n\u001B[1;32m----> 6\u001B[0m     loaded_pairs_dic \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mload(json_file)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Now, loaded_pairs_dic contains the dictionary from the JSON file\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m#print(loaded_pairs_dic)\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loaded_pairs_dic\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\json\\__init__.py:293\u001B[0m, in \u001B[0;36mload\u001B[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[0;32m    274\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload\u001B[39m(fp, \u001B[38;5;241m*\u001B[39m, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, object_hook\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, parse_float\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    275\u001B[0m         parse_int\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, parse_constant\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, object_pairs_hook\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw):\n\u001B[0;32m    276\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001B[39;00m\n\u001B[0;32m    277\u001B[0m \u001B[38;5;124;03m    a JSON document) to a Python object.\u001B[39;00m\n\u001B[0;32m    278\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    291\u001B[0m \u001B[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001B[39;00m\n\u001B[0;32m    292\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 293\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loads(fp\u001B[38;5;241m.\u001B[39mread(),\n\u001B[0;32m    294\u001B[0m         \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mcls\u001B[39m, object_hook\u001B[38;5;241m=\u001B[39mobject_hook,\n\u001B[0;32m    295\u001B[0m         parse_float\u001B[38;5;241m=\u001B[39mparse_float, parse_int\u001B[38;5;241m=\u001B[39mparse_int,\n\u001B[0;32m    296\u001B[0m         parse_constant\u001B[38;5;241m=\u001B[39mparse_constant, object_pairs_hook\u001B[38;5;241m=\u001B[39mobject_pairs_hook, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\json\\__init__.py:346\u001B[0m, in \u001B[0;36mloads\u001B[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[0;32m    341\u001B[0m     s \u001B[38;5;241m=\u001B[39m s\u001B[38;5;241m.\u001B[39mdecode(detect_encoding(s), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msurrogatepass\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[0;32m    344\u001B[0m         parse_int \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m parse_float \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[0;32m    345\u001B[0m         parse_constant \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_pairs_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kw):\n\u001B[1;32m--> 346\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _default_decoder\u001B[38;5;241m.\u001B[39mdecode(s)\n\u001B[0;32m    347\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    348\u001B[0m     \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m JSONDecoder\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\json\\decoder.py:337\u001B[0m, in \u001B[0;36mJSONDecoder.decode\u001B[1;34m(self, s, _w)\u001B[0m\n\u001B[0;32m    332\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode\u001B[39m(\u001B[38;5;28mself\u001B[39m, s, _w\u001B[38;5;241m=\u001B[39mWHITESPACE\u001B[38;5;241m.\u001B[39mmatch):\n\u001B[0;32m    333\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001B[39;00m\n\u001B[0;32m    334\u001B[0m \u001B[38;5;124;03m    containing a JSON document).\u001B[39;00m\n\u001B[0;32m    335\u001B[0m \n\u001B[0;32m    336\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 337\u001B[0m     obj, end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw_decode(s, idx\u001B[38;5;241m=\u001B[39m_w(s, \u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mend())\n\u001B[0;32m    338\u001B[0m     end \u001B[38;5;241m=\u001B[39m _w(s, end)\u001B[38;5;241m.\u001B[39mend()\n\u001B[0;32m    339\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m end \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(s):\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\json\\decoder.py:355\u001B[0m, in \u001B[0;36mJSONDecoder.raw_decode\u001B[1;34m(self, s, idx)\u001B[0m\n\u001B[0;32m    353\u001B[0m     obj, end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscan_once(s, idx)\n\u001B[0;32m    354\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m--> 355\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m JSONDecodeError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpecting value\u001B[39m\u001B[38;5;124m\"\u001B[39m, s, err\u001B[38;5;241m.\u001B[39mvalue) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    356\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj, end\n",
      "\u001B[1;31mJSONDecodeError\u001B[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "def get_data(ticker, start, end):\n",
    "    return yf.download(ticker, start, end)['Close']\n",
    "\n",
    "def main():\n",
    "    final_pair_list = []\n",
    "    adf_pvalue_thres = 0.05\n",
    "    pair_to_spread = {} \n",
    "    \n",
    "    pairs_dict = load_pairs()\n",
    "    print(pairs_dict)\n",
    "\n",
    "    for ticker1 in pairs_dict.keys():\n",
    "        tickers = copy.copy(pairs_dict[ticker1])\n",
    "        if isinstance(tickers, str):\n",
    "            tickers = [tickers]\n",
    "            \n",
    "        for ticker2 in tickers:\n",
    "            pair_name = ticker1 + '_' + ticker2\n",
    "            print(pair_name)\n",
    "            asset1 = get_data(ticker1,start,end)\n",
    "            asset2 = get_data(ticker2,start,end)\n",
    "            plot_assets(asset1, asset2, ticker1, ticker2)\n",
    "            pair_to_spread[pair_name], spread = regression_analysis(asset1, asset2, ticker1, ticker2)\n",
    "            does_pass_adf = run_adf_test(ticker1,ticker2,spread, adf_pvalue_thres)\n",
    "            if does_pass_adf:\n",
    "                final_pair_list.append(ticker1+\"_\"+ticker2)\n",
    "    \n",
    "    print(len(final_pair_list))\n",
    "    final_pair_file_path = \"data/final_pair.csv\"\n",
    "    with open(final_pair_file_path, \"w\", newline=\"\") as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        for pair in final_pair_list:\n",
    "            tickers = pair.split(\"_\")\n",
    "            writer.writerow([tickers[0],tickers[1]])\n",
    "        \n",
    "main()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T23:29:53.309518800Z",
     "start_time": "2023-10-09T23:29:53.213180900Z"
    }
   },
   "id": "4d183ff655a03645"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
