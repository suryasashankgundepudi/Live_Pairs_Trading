{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-09T15:40:09.597131700Z",
     "start_time": "2023-11-09T15:40:09.500500200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for Stationarity for each pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import statsmodels.api as sm\n",
    "import datetime\n",
    "import os \n",
    "import csv\n",
    "import copy \n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "random.seed(1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T15:40:09.618422900Z",
     "start_time": "2023-11-09T15:40:09.507507900Z"
    }
   },
   "id": "773ee2908b289925"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Function: Load data obtained from the identify pairs notebook"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T15:40:09.672359400Z",
     "start_time": "2023-11-09T15:40:09.513617300Z"
    }
   },
   "id": "b5aaa4e9abe85461"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def load_pairs():\n",
    "    file_path = \"data/pairs_names.json\"\n",
    "    \n",
    "    # Read the JSON file as a dictionary\n",
    "    with open(file_path, \"r\") as json_file:\n",
    "        loaded_pairs_dic = json.load(json_file)\n",
    "    \n",
    "    # Now, loaded_pairs_dic contains the dictionary from the JSON file\n",
    "    #print(loaded_pairs_dic)\n",
    "    return loaded_pairs_dic\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T15:40:09.672359400Z",
     "start_time": "2023-11-09T15:40:09.523073800Z"
    }
   },
   "id": "ac95232b0e4efa59"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Enable to use start & end dates:\n",
    "start = datetime.date.today() - datetime.timedelta(days=430)\n",
    "end = datetime.date.today() - datetime.timedelta(days=60)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T15:40:09.672359400Z",
     "start_time": "2023-11-09T15:40:09.534664500Z"
    }
   },
   "id": "dddbd0a845280fd4"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Function: Plotting price movement of two assets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T15:40:09.672359400Z",
     "start_time": "2023-11-09T15:40:09.546160700Z"
    }
   },
   "id": "fd90d2f5a9dc2e1e"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_assets(asset1, asset2, ticker1, ticker2):\n",
    "    fig = make_subplots(rows=2,\n",
    "                    cols=1,\n",
    "                    subplot_titles=(\"asset2\", \"asset1\"))\n",
    "\n",
    "    fig.append_trace(go.Scatter(x=asset2.index,\n",
    "                                y=asset2,\n",
    "                                ),\n",
    "                     row=1, col=1)\n",
    "    \n",
    "    fig.append_trace(go.Scatter(x=asset1.index,\n",
    "                                y=asset1,\n",
    "                                ),\n",
    "                     row=2, col=1)\n",
    "    \n",
    "    # Update yaxis properties\n",
    "    fig.update_yaxes(title_text=\"Price\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Date\",  row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Price\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Date\",  row=2, col=1)\n",
    "    \n",
    "    #fig.show()\n",
    "    if not os.path.exists(\"img/\"):\n",
    "        os.mkdir(\"img/\")\n",
    "        print(\"Image Directory Created!\")\n",
    "    \n",
    "    file_path = \"img/\" + ticker1 + \"_\" + ticker2 + \".html\" \n",
    "    fig.write_html(file_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T15:40:09.672359400Z",
     "start_time": "2023-11-09T15:40:09.556328700Z"
    }
   },
   "id": "b3289fb34c2aca02"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Function: Run OLS Regression and calculating spread"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T15:40:09.672359400Z",
     "start_time": "2023-11-09T15:40:09.572137800Z"
    }
   },
   "id": "6570c27b3cbf9044"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def regression_analysis(asset1, asset2, ticker1, ticker2):\n",
    "\n",
    "    # adding a constant variable to the asset1 time series for the intercept value \n",
    "    asset1 = sm.add_constant(asset1, prepend=False)\n",
    "    \n",
    "    # Running the OLS function with asset2 as the dependent variable and asset1 as the dependent variable\n",
    "    ols = sm.OLS(asset2, asset1)\n",
    "    \n",
    "    # Saving the results of the OLS model into a variable\n",
    "    output = ols.fit()\n",
    "    print(\"Completed Training\")\n",
    "    \n",
    "    #print(output.params)\n",
    "    # Getting the beta from the OLS results. Close means the close price of asset1\n",
    "    beta = output.params[\"Close\"]\n",
    "    \n",
    "    # Dropping the const column in the dependent variable\n",
    "    asset1.drop(columns=\"const\", inplace = True)\n",
    "    \n",
    "    # Calculating spread\n",
    "    spread = asset2 - beta*asset1[\"Close\"]\n",
    "    \n",
    "    fig = go.Figure(go.Scatter(y = spread))\n",
    "    \n",
    "    fig.update_layout(title = \"Spread between \" + ticker2 + \" and \" + ticker1)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Date\")\n",
    "    fig.update_yaxes(title_text=\"Spread\")\n",
    "    \n",
    "    file_path = \"img/Spread_\" + ticker1 + \"_\" + ticker2 + \".html\"\n",
    "    fig.write_html(file_path)\n",
    "    \n",
    "    #fig.show()\n",
    "    \n",
    "    return beta, spread\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T15:40:09.672359400Z",
     "start_time": "2023-11-09T15:40:09.586712Z"
    }
   },
   "id": "e2581d18c879598e"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Function: Perform Augmented Dickey Fuller Test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T15:40:09.672359400Z",
     "start_time": "2023-11-09T15:40:09.602638600Z"
    }
   },
   "id": "97e94f3395a34290"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "def run_adf_test(ticker1, ticker2, spread, pvalue_thres):\n",
    "    result = adfuller(spread)\n",
    "    does_pass = result[1] < pvalue_thres\n",
    "    if does_pass:\n",
    "        print(f'spread between {ticker1} and {ticker2} passed ADF stationarity test')\n",
    "    else:\n",
    "        print(f'spread between {ticker1} and {ticker2} failed ADF stationarity test')    \n",
    "    return does_pass\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T15:40:09.672359400Z",
     "start_time": "2023-11-09T15:40:09.606640600Z"
    }
   },
   "id": "d7206e2b73b3acec"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "#1. p-value > 0.05: Fail to reject the null hypothesis (H0), the data has a unit root and is non-stationary.\n",
    "#2. p-value <= 0.05: Reject the null hypothesis (H0), the data does not have a unit root and is stationary.\n",
    "\n",
    "#**Since the p value is greater than 0.05 we fail to reject the null hypothesis, the time series is not stationary**\n",
    "\n",
    "#If it was accepted the code would be as follows\n",
    "#```python\n",
    "#accepted_pairs = []\n",
    "#accepted_pairs.append(target_pair[0] + \"_\" + target_pair[1]) \n",
    "#```\n",
    "\n",
    "#You don't need to print out the values from ADF just check if the 5% level is less than or equal to 0.05 and save it into the list. \n",
    "\n",
    "\n",
    "#Once the list is complete for all assets you would need to save it as a text file for later use"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T15:40:09.672359400Z",
     "start_time": "2023-11-09T15:40:09.618422900Z"
    }
   },
   "id": "58c00cb295dbf9f8"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ICE': ['HDB'], 'ING': ['HDB'], 'ITUB': ['BX'], 'JPM': ['APO', 'HDB'], 'MA': ['HDB', 'JPM'], 'MMC': ['ICE'], 'MS': ['C'], 'PYPL': ['HDB'], 'RY': ['BNS', 'MS'], 'SMFG': ['BBVA', 'HDB'], 'UBS': ['HDB', 'PGR', 'SMFG'], 'USB': ['TD'], 'V': ['BBVA', 'HDB', 'PYPL', 'SAN', 'UBS']}\n",
      "ICE_HDB\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between ICE and HDB failed ADF stationarity test\n",
      "ING_HDB\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between ING and HDB passed ADF stationarity test\n",
      "ITUB_BX\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between ITUB and BX failed ADF stationarity test\n",
      "JPM_APO\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between JPM and APO failed ADF stationarity test\n",
      "JPM_HDB\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between JPM and HDB passed ADF stationarity test\n",
      "MA_HDB\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between MA and HDB passed ADF stationarity test\n",
      "MA_JPM\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between MA and JPM failed ADF stationarity test\n",
      "MMC_ICE\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between MMC and ICE passed ADF stationarity test\n",
      "MS_C\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between MS and C failed ADF stationarity test\n",
      "PYPL_HDB\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between PYPL and HDB failed ADF stationarity test\n",
      "RY_BNS\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between RY and BNS passed ADF stationarity test\n",
      "RY_MS\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between RY and MS passed ADF stationarity test\n",
      "SMFG_BBVA\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between SMFG and BBVA passed ADF stationarity test\n",
      "SMFG_HDB\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between SMFG and HDB failed ADF stationarity test\n",
      "UBS_HDB\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between UBS and HDB failed ADF stationarity test\n",
      "UBS_PGR\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between UBS and PGR passed ADF stationarity test\n",
      "UBS_SMFG\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between UBS and SMFG failed ADF stationarity test\n",
      "USB_TD\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between USB and TD passed ADF stationarity test\n",
      "V_BBVA\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between V and BBVA passed ADF stationarity test\n",
      "V_HDB\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between V and HDB failed ADF stationarity test\n",
      "V_PYPL\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between V and PYPL passed ADF stationarity test\n",
      "V_SAN\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between V and SAN passed ADF stationarity test\n",
      "V_UBS\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Completed Training\n",
      "spread between V and UBS failed ADF stationarity test\n",
      "   Asset1 Asset2      Beta\n",
      "0     ING    HDB  1.179973\n",
      "1     JPM    HDB  0.165720\n",
      "2      MA    HDB  0.059619\n",
      "3     MMC    ICE  0.557555\n",
      "4      RY    BNS  0.445733\n",
      "5      RY     MS  1.154786\n",
      "6    SMFG   BBVA  0.864634\n",
      "7     UBS    PGR  1.363218\n",
      "8     USB     TD  0.472484\n",
      "9       V   BBVA  0.058249\n",
      "10      V   PYPL -0.369018\n",
      "11      V    SAN  0.026201\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "def get_data(ticker, start, end):\n",
    "    return yf.download(ticker, start, end)['Close']\n",
    "\n",
    "def main():\n",
    "    final_pair_df = None\n",
    "    \n",
    "    adf_pvalue_thres = 0.05\n",
    "    pair_to_beta = {} \n",
    "    \n",
    "    pairs_dict = load_pairs()\n",
    "    print(pairs_dict)\n",
    "\n",
    "    for ticker1 in pairs_dict.keys():\n",
    "        tickers = copy.copy(pairs_dict[ticker1])\n",
    "        if isinstance(tickers, str):\n",
    "            tickers = [tickers]\n",
    "            \n",
    "        for ticker2 in tickers:\n",
    "            pair_name = ticker1 + '_' + ticker2\n",
    "            print(pair_name)\n",
    "            asset1 = get_data(ticker1,start,end)\n",
    "            asset2 = get_data(ticker2,start,end)\n",
    "            plot_assets(asset1, asset2, ticker1, ticker2)\n",
    "            beta, spread = regression_analysis(asset1, asset2, ticker1, ticker2)\n",
    "            pair_to_beta[pair_name] = beta\n",
    "            does_pass_adf = run_adf_test(ticker1,ticker2,spread, adf_pvalue_thres)\n",
    "            if does_pass_adf:\n",
    "                data_row = pd.DataFrame(data={\"Asset1\":ticker1, \"Asset2\": ticker2, \"Beta\": beta}, index=[0])\n",
    "                if final_pair_df is None:\n",
    "                    final_pair_df = data_row\n",
    "                else:\n",
    "                    final_pair_df = pd.concat([final_pair_df, data_row],ignore_index=True)\n",
    "                    \n",
    "    print(final_pair_df)\n",
    "    print(len(final_pair_df))\n",
    "    final_pair_file_path = \"data/final_pairs.csv\"\n",
    "    final_pair_df.to_csv(final_pair_file_path)\n",
    "    '''\n",
    "    with open(final_pair_file_path, \"w\", newline=\"\") as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        for pair in final_pair_list:\n",
    "            tickers = pair.split(\"_\")\n",
    "            writer.writerow([tickers[0],tickers[1],pair_to_beta[pair]])\n",
    "    '''\n",
    "        \n",
    "main()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T15:40:24.854338900Z",
     "start_time": "2023-11-09T15:40:09.634131500Z"
    }
   },
   "id": "4d183ff655a03645"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
